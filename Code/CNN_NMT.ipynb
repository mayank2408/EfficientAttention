{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XkJHZoYWrpeo",
    "outputId": "392771f2-f2c8-4009-889b-d5df4c3dc12a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext==0.6.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/17/e7c588245aece7aa93f360894179374830daf60d7ed0bbb59332de3b3b61/torchtext-0.6.0-py3-none-any.whl (64kB)\n",
      "\r",
      "\u001b[K     |█████                           | 10kB 22.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▏                     | 20kB 27.9MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▎                | 30kB 33.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 40kB 31.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▌      | 51kB 31.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▋ | 61kB 34.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 71kB 10.4MB/s \n",
      "\u001b[?25hCollecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
      "\r",
      "\u001b[K     |▎                               | 10kB 25.3MB/s eta 0:00:01\r",
      "\u001b[K     |▋                               | 20kB 34.0MB/s eta 0:00:01\r",
      "\u001b[K     |▉                               | 30kB 39.3MB/s eta 0:00:01\r",
      "\u001b[K     |█▏                              | 40kB 32.1MB/s eta 0:00:01\r",
      "\u001b[K     |█▌                              | 51kB 34.0MB/s eta 0:00:01\r",
      "\u001b[K     |█▊                              | 61kB 24.8MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 71kB 26.6MB/s eta 0:00:01\r",
      "\u001b[K     |██▍                             | 81kB 23.9MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 92kB 22.4MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 102kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |███▎                            | 112kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |███▌                            | 122kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |███▉                            | 133kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |████▏                           | 143kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |████▍                           | 153kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |████▊                           | 163kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 174kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 184kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████▋                          | 194kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████▉                          | 204kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████▏                         | 215kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████▌                         | 225kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████▊                         | 235kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 245kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████▍                        | 256kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 266kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 276kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 286kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 296kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████▉                       | 307kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 317kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▍                      | 327kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 337kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 348kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 358kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 368kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▉                     | 378kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▏                    | 389kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▌                    | 399kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▊                    | 409kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 419kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 430kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 440kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 450kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 460kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▌                  | 471kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▉                  | 481kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 491kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▍                 | 501kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▊                 | 512kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 522kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▎                | 532kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 542kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▉                | 552kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▏               | 563kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▌               | 573kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▊               | 583kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 593kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▍              | 604kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▋              | 614kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 624kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▏             | 634kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▌             | 645kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▉             | 655kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 665kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▍            | 675kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▊            | 686kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 696kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▎           | 706kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▋           | 716kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 727kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▏          | 737kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▌          | 747kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▊          | 757kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 768kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▎         | 778kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 788kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 798kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▏        | 808kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▌        | 819kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▉        | 829kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 839kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▍       | 849kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▊       | 860kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 870kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▎      | 880kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 890kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▉      | 901kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 911kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 921kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▊     | 931kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 942kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▎    | 952kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▋    | 962kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 972kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 983kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 993kB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 1.0MB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 1.0MB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 1.0MB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▊  | 1.0MB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 1.0MB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 1.1MB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▋ | 1.1MB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 1.1MB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 1.1MB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▍| 1.1MB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▊| 1.1MB 23.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 1.1MB 23.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.7.0+cu101)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.15.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (2.23.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (4.41.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.18.5)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (0.7)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (3.7.4.3)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (0.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n",
      "Installing collected packages: sentencepiece, torchtext\n",
      "  Found existing installation: torchtext 0.3.1\n",
      "    Uninstalling torchtext-0.3.1:\n",
      "      Successfully uninstalled torchtext-0.3.1\n",
      "Successfully installed sentencepiece-0.1.94 torchtext-0.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext==0.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "WV2w4Lv4EvGs"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "icEriea939WG"
   },
   "outputs": [],
   "source": [
    "from torchtext.data.metrics import bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "TJHMGSBjE4mP"
   },
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B9GFJAwpk8dn",
    "outputId": "db227050-ac50-49fc-e8cf-568e0aed796a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (50.3.2)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
      "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n",
      "Collecting de_core_news_sm==2.2.5\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9MB)\n",
      "\u001b[K     |████████████████████████████████| 14.9MB 14.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.4)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (50.3.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.18.5)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.6.20)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.0)\n",
      "Building wheels for collected packages: de-core-news-sm\n",
      "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-cp36-none-any.whl size=14907056 sha256=72f5270fe51ef0ac256433bf4f8bf8ea6be5091db4dd833de5c35d8fb644712c\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ysok0naj/wheels/ba/3f/ed/d4aa8e45e7191b7f32db4bfad565e7da1edbf05c916ca7a1ca\n",
      "Successfully built de-core-news-sm\n",
      "Installing collected packages: de-core-news-sm\n",
      "Successfully installed de-core-news-sm-2.2.5\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('de_core_news_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
      "/usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
      "You can now load the model via spacy.load('de')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en\n",
    "!python -m spacy download de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "rxIAuAgZFIRW"
   },
   "outputs": [],
   "source": [
    "spacy_de = spacy.load('de')\n",
    "spacy_en = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "HlHeF38BFIVx"
   },
   "outputs": [],
   "source": [
    "def tokenize_de(text):\n",
    "    \"\"\"\n",
    "    Tokenizes German text from a string into a list of strings\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    \"\"\"\n",
    "    Tokenizes English text from a string into a list of strings\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "Op8BWoVdFIeb"
   },
   "outputs": [],
   "source": [
    "SRC = Field(tokenize = tokenize_de, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True, \n",
    "            include_lengths = True)\n",
    "\n",
    "TRG = Field(tokenize = tokenize_en, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYJati0lFIiz",
    "outputId": "54550267-f5df-4f86-e015-072b2cb2246d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading training.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:01<00:00, 917kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading validation.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 274kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading mmt_task1_test2016.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 263kB/s]\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'), \n",
    "                                                    fields = (SRC, TRG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "3eiXz7FgFW5H"
   },
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data, min_freq = 2)\n",
    "TRG.build_vocab(train_data, min_freq = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "fS2OYJMFF4lP"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "     batch_size = BATCH_SIZE,\n",
    "     sort_within_batch = True,\n",
    "     sort_key = lambda x : len(x.src),\n",
    "     device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "HST_c8I5F4o0"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, levels, k, attention):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
    "\n",
    "        self.cnn_level = nn.Conv1d(enc_hid_dim*2,enc_hid_dim*2,kernel_size=k,stride=k)\n",
    "\n",
    "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
    "        \n",
    "        self.output_level = nn.Linear(enc_hid_dim * 2, enc_hid_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.dropout2 = nn.Dropout(dropout*1.25)\n",
    "        \n",
    "        self.levels = levels\n",
    "\n",
    "        self.k = k\n",
    "\n",
    "        self.attention = attention\n",
    "\n",
    "    def forward(self, src, src_len):\n",
    "        \n",
    "        #src = [src len, batch size], src len = max_len\n",
    "        #src_len = [batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        batch_size = src.shape[1]\n",
    "        #embedded = [src len, batch size, emb dim]\n",
    "\n",
    "        src_len=src_len.cpu()       \n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len)\n",
    "                \n",
    "        packed_outputs, hidden = self.rnn(packed_embedded)\n",
    "                              \n",
    "        #packed_outputs is a packed sequence containing all hidden states\n",
    "        #hidden is now from the final non-padded element in the batch\n",
    "            \n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs)\n",
    "        enc_hid_dim=list(outputs.shape)[2] \n",
    "        #outputs is now a non-packed sequence, all hidden states obtained\n",
    "        #  when the input is a pad token are all zeros\n",
    "            \n",
    "        #outputs = [src len, batch size, hid dim * num directions]\n",
    "        #hidden = [n layers * num directions, batch size, hid dim]\n",
    "        \n",
    "        #hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
    "        #outputs are always from the last layer\n",
    "        \n",
    "        #hidden [-2, :, : ] is the last of the forwards RNN \n",
    "        #hidden [-1, :, : ] is the last of the backwards RNN\n",
    "        \n",
    "        #initial decoder hidden is final hidden state of the forwards and backwards \n",
    "        #  encoder RNNs fed through a linear layer\n",
    "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
    "        \n",
    "        #outputs = [src len, batch size, enc hid dim * 2]\n",
    "        #hidden = [batch size, dec hid dim]\n",
    "\n",
    "\n",
    "        mask = torch.zeros(list(outputs.shape)[1],list(outputs.shape)[0],device=device)\n",
    "        #mask = [batch size, src len]\n",
    "        for q in range(list(outputs.shape)[1]):\n",
    "          mask[q,:src_len[q]]=1\n",
    "\n",
    "        length_of_seq = list(outputs.shape)[0]\n",
    "\n",
    "        if (list(outputs.shape)[0]%self.k !=0):\n",
    "            \n",
    "            temp_pad=(outputs.shape[0]//k +1)*k\n",
    "            padded_outputs=torch.zeros((temp_pad,list(outputs.shape)[1],list(outputs.shape)[2]),device=device)\n",
    "            padded_outputs[:list(outputs.shape)[0],:,:]=outputs\n",
    "            mask_temp=torch.zeros((list(outputs.shape)[1], temp_pad),device=device)\n",
    "            mask_temp[:, :list(mask.shape)[1]]=mask\n",
    "        else:\n",
    "            padded_outputs = outputs\n",
    "            mask_temp = mask\n",
    "        \n",
    "        final_outputs=[padded_outputs]\n",
    "        masks=[mask_temp]\n",
    "\n",
    "        if (self.levels>1):\n",
    "            for i in range(1,self.levels):\n",
    "                \n",
    "                temp_outputs=self.dropout2(torch.nn.functional.relu(self.cnn_level(final_outputs[-1].permute(1,2,0))))\n",
    "                # [batch_size, hidden_dim, T/k]\n",
    "                #print('shape',temp_outputs.shape)\n",
    "                temp_outputs=temp_outputs.permute(2,0,1)\n",
    "                length_of_seq = list(temp_outputs.shape)[0]\n",
    "                #outputs = [src len, batch size, enc hid dim * 2]\n",
    "\n",
    "                \n",
    "                \n",
    "                padded_outputs=final_outputs[-1].permute(1,0,2)\n",
    "                #padded_outputs=padded_outputs.reshape(batch_size,self.k,-1,enc_hid_dim*2)\n",
    "                #padded_outputs=padded_outputs.permute(0,2,1,3)\n",
    "                padded_outputs=padded_outputs.reshape(-1,self.k,enc_hid_dim)\n",
    "                #[batch size*T/k, k, enc hid dim * 2]\n",
    "                #print('padded_outputs.shape:',padded_outputs.shape)\n",
    "\n",
    "                #mask_temp=mask_temp.reshape(batch_size,self.k,-1)\n",
    "                #mask_temp=mask_temp.permute(0,2,1)\n",
    "                mask_temp=masks[-1].reshape(-1,self.k)\n",
    "                #[batch size*T/k, k]\n",
    "\n",
    "                temp_padded_outputs=temp_outputs\n",
    "                temp_padded_outputs=temp_padded_outputs.permute(1,0,2)\n",
    "                #temp_padded_outputs=temp_padded_outputs.unsqueeze(3)\n",
    "                temp_padded_outputs=temp_padded_outputs.reshape(-1,enc_hid_dim)\n",
    "                #[batch size*T/k, enc hid dim * 2]\n",
    "\n",
    "                #make mask\n",
    "                \n",
    "                a=self.attention(temp_padded_outputs,padded_outputs.permute(1,0,2),mask_temp)\n",
    "                a = a.unsqueeze(1)\n",
    "                weighted = torch.bmm(a, padded_outputs)\n",
    "                #weighted = [batch size*T/k, 1, enc hid dim * 2]\n",
    "\n",
    "                weighted=weighted.squeeze(1)\n",
    "                weighted_pad=weighted.view(batch_size,-1,enc_hid_dim)\n",
    "\n",
    "                level_outputs = weighted_pad.permute(1,0,2)\n",
    "                if (list(level_outputs.shape)[0]%self.k ==0):\n",
    "                    padded_outputs=level_outputs\n",
    "                else:\n",
    "                    temp_pad=(list(level_outputs.shape)[0]//k +1)*k\n",
    "                    padded_outputs=torch.zeros((temp_pad,list(level_outputs.shape)[1],list(level_outputs.shape)[2]),device=device)\n",
    "                    padded_outputs[:list(level_outputs.shape)[0],:,:]=level_outputs\n",
    "\n",
    "                #update src_len, masks\n",
    "                #print(type(src_len))\n",
    "                b = (src_len // self.k)\n",
    "                b[src_len % self.k != 0] += 1\n",
    "                src_len=b\n",
    "                #print(type(src_len))\n",
    "                outputs=padded_outputs\n",
    "                mask = torch.zeros(list(outputs.shape)[1],list(outputs.shape)[0],device=device)  #mask = [batch size, src len]\n",
    "                for q in range(list(outputs.shape)[1]):\n",
    "                    mask[q,:src_len[q]]=1\n",
    "                masks.append(mask)\n",
    "                final_outputs.append(outputs)\n",
    "                #print(\"encoder_outputs:\",outputs.shape)\n",
    "        \n",
    "        return final_outputs, hidden, masks\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "hFMishKJF4s4"
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
    "        #print('self.attn',(enc_hid_dim * 2) + dec_hid_dim)\n",
    "        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs, mask):\n",
    "        \n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        \n",
    "        #repeat decoder hidden state src_len times\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "  \n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        \n",
    "        #hidden = [batch size, src len, dec hid dim]\n",
    "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
    "        #print(torch.cat((hidden, encoder_outputs), dim = 2).shape)\n",
    "        #print('hidden.shape,encoder_outputs.shape:',hidden.shape,encoder_outputs.shape)\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n",
    "        #energy = [batch size, src len, dec hid dim]\n",
    "\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        \n",
    "        #attention = [batch size, src len]\n",
    "        \n",
    "        attention = attention.masked_fill(mask == 0, -1e10)\n",
    "        \n",
    "        return F.softmax(attention, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "qiMd9A_OF4vu"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention, k):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
    "        \n",
    "        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.k=k\n",
    "        \n",
    "    def forward(self, input, hidden, encoder_outputs, masks):\n",
    "             \n",
    "        #input = [batch size]\n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        #encoder_outputs = list of this size[src len, batch size, enc hid dim * 2]\n",
    "        #mask = list of this size[batch size, src len]\n",
    "        \n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        #input = [1, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        \n",
    "        #embedded = [1, batch size, emb dim]\n",
    "        batch_size = list(encoder_outputs[0].shape)[1]\n",
    "        enc_hid_dim = list(encoder_outputs[0].shape)[2]//2\n",
    "        prob_remaining=torch.ones(batch_size).to(device)\n",
    "        #top1=0\n",
    "        weighted=torch.zeros((batch_size, 1, enc_hid_dim * 2)).to(device)\n",
    "\n",
    "        batch_number=torch.arange(batch_size,device=device)\n",
    "\n",
    "        for i in range(len(encoder_outputs)-1,-1,-1):\n",
    "            \n",
    "            \n",
    "            if (i==(len(encoder_outputs)-1)):\n",
    "\n",
    "                current_outputs = encoder_outputs[i]\n",
    "\n",
    "                current_mask = masks[i]\n",
    "            else:\n",
    "                encoder_out_temp=encoder_outputs[i]\n",
    "                mask_temp = masks[i]\n",
    "                '''if (list(encoder_outputs[i].shape)[0]%self.k ==0):\n",
    "                    encoder_out_temp=encoder_outputs[i]\n",
    "                    mask_temp=masks[i]\n",
    "                    \n",
    "                else:\n",
    "                    temp_pad=(list(encoder_outputs[i].shape)[0]//k +1)*k\n",
    "                    encoder_out_temp=torch.zeros((temp_pad,list(encoder_outputs[i].shape)[1],list(encoder_outputs[i].shape)[2]))\n",
    "\n",
    "                    encoder_out_temp[:list(encoder_outputs[i].shape)[0],:,:]=encoder_outputs[i]\n",
    "                    mask_temp=torch.zeros((list(encoder_outputs[i].shape)[1], temp_pad))\n",
    "                    mask_temp[:, :list(masks[i].shape)[1]]=masks[i]'''\n",
    "\n",
    "                current_outputs=torch.zeros((self.k,list(encoder_outputs[i].shape)[1],list(encoder_outputs[i].shape)[2]), device=device)\n",
    "                current_mask=torch.zeros((list(encoder_outputs[i].shape)[1],self.k),device=device)\n",
    "                \n",
    "                #for z in range(list(top1.shape)[0]):\n",
    "                for z in range(self.k):\n",
    "                    #print(\"encoder_out_temp.shape,current_outputs.shape\",encoder_out_temp.shape,current_outputs.shape)\n",
    "                    #current_outputs[:,z,:] = encoder_out_temp[top1[z]:top1[z]+k,z,:]\n",
    "            \n",
    "                    #current_mask[z,:] = mask_temp[z,top1[z]:top1[z]+k]\n",
    "                   \n",
    "                    current_outputs[z,:,:] = encoder_out_temp[top1+z,batch_number,:]\n",
    "            \n",
    "                    current_mask[:,z] = mask_temp[batch_number,top1+z]\n",
    "                \n",
    "                \n",
    "                #current_outputs = encoder_outputs[i][top1:min(top1+k,list(encoder_outpus[i].shape)[0],:,:]\n",
    "            \n",
    "                #current_mask =masks[i][top1:min(top1+k,list(encoder_outpus[i].shape)[0],:,:]\n",
    "            \n",
    "            #current_outputs=current_outputs.to(device)\n",
    "            #current_mask=current_mask.to(device)\n",
    "            a = self.attention(hidden, current_outputs, current_mask)\n",
    "                    \n",
    "            #a = [batch size, src len]\n",
    "            \n",
    "            \n",
    "            top1 = a.argmax(1)\n",
    "            prob_remaining_prev=prob_remaining\n",
    "            #print(\"tuple:\",a.max(1),prob_remaining_prev)\n",
    "            prob_remaining = a.max(1)[0]*prob_remaining_prev #element-wise multiplication\n",
    "            # [batch_size]\n",
    "\n",
    "            a = a.unsqueeze(1)\n",
    "            #a = [batch size, 1, src len]\n",
    "            \n",
    "            #current_outputs[top1,:,:]=0 #to not attend to max weights\n",
    "            current_outputs=current_outputs.clone()\n",
    "            #start_t = time.time()\n",
    "            if i!=0:\n",
    "\n",
    "                current_outputs[top1,batch_number,:]=0\n",
    "            \n",
    "            #end_t = time.time()\n",
    "            #epoch_mins, epoch_secs = epoch_time(start_t, end_t)\n",
    "            #print('de_timestamp, loop time:',epoch_mins, epoch_secs)\n",
    "            current_outputs = current_outputs.permute(1, 0, 2)\n",
    "            \n",
    "            #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
    "            #print(\"tuple:\",a.shape,current_outputs.shape,prob_remaining_prev)\n",
    "\n",
    "            weighted_temp = torch.bmm(a, current_outputs)*(prob_remaining_prev.view(-1,1,1)) #elementwise multplication+broadcasting\n",
    "            #weighted = [batch size, 1, enc hid dim * 2]    [batch_size]\n",
    "\n",
    "            weighted=weighted+weighted_temp\n",
    "            \n",
    "        weighted = weighted.permute(1, 0, 2)\n",
    "        \n",
    "        #weighted = [1, batch size, enc hid dim * 2]\n",
    "        \n",
    "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
    "        \n",
    "        #rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\n",
    "            \n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "        \n",
    "        #output = [seq len, batch size, dec hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, dec hid dim]\n",
    "        \n",
    "        #seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
    "        #output = [1, batch size, dec hid dim]\n",
    "        #hidden = [1, batch size, dec hid dim]\n",
    "        #this also means that output == hidden\n",
    "        assert (output == hidden).all()\n",
    "        \n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        \n",
    "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n",
    "        \n",
    "        #prediction = [batch size, output dim]\n",
    "            \n",
    "        return prediction, hidden.squeeze(0), a.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "nlELWxmSF41J"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, src_pad_idx, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.device = device\n",
    "        \n",
    "    def create_mask(self, src):\n",
    "        mask = (src != self.src_pad_idx).permute(1, 0)\n",
    "        return mask\n",
    "        \n",
    "    def forward(self, src, src_len, trg, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        #src_len = [batch size]\n",
    "        #trg = [trg len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
    "                    \n",
    "        batch_size = src.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        #encoder_outputs is all hidden states of the input sequence, back and forwards\n",
    "        #hidden is the final forward and backward hidden states, passed through a linear layers\n",
    "        start_t=time.time()\n",
    "\n",
    "        encoder_outputs, hidden, masks = self.encoder(src, src_len)\n",
    "\n",
    "        end_t=time.time()\n",
    "        epoch_mins, epoch_secs = epoch_time(start_t, end_t)\n",
    "        #print('en_time:',epoch_mins, epoch_secs)\n",
    "                \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input = trg[0,:]\n",
    "        \n",
    "        mask = self.create_mask(src)\n",
    "\n",
    "        #mask = [batch size, src len]\n",
    "        start_t=time.time()       \n",
    "        for t in range(1, trg_len):\n",
    "            \n",
    "            #insert input token embedding, previous hidden state, all encoder hidden states \n",
    "            #  and mask\n",
    "            #receive output tensor (predictions) and new hidden state\n",
    "            output, hidden, _ = self.decoder(input, hidden, encoder_outputs, masks)\n",
    "            \n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            \n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1) \n",
    "            \n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted tokenend\n",
    "            input = trg[t] if teacher_force else top1\n",
    "        end_t=time.time()\n",
    "        epoch_mins, epoch_secs = epoch_time(start_t, end_t)\n",
    "        #print('de_time:',epoch_mins, epoch_secs)   \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "YOI8FRLqFW8p"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "cd0zIozWL0XQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "e9B-OdzeFXBv"
   },
   "outputs": [],
   "source": [
    "#change here\n",
    "k=3\n",
    "levels=2\n",
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "ENC_HID_DIM = 512\n",
    "DEC_HID_DIM = 512\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
    "\n",
    "dec_attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "enc_attn = Attention(ENC_HID_DIM, ENC_HID_DIM * 2)\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT,levels,k,enc_attn)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, dec_attn,k)\n",
    "\n",
    "model = Seq2Seq(enc, dec, SRC_PAD_IDX, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DFnectssK-bz",
    "outputId": "ba6e6d5e-1d08-44af-fc45-83032b98e656"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(7855, 256)\n",
       "    (rnn): GRU(256, 512, bidirectional=True)\n",
       "    (cnn_level): Conv1d(1024, 1024, kernel_size=(3,), stride=(3,))\n",
       "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (output_level): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (dropout2): Dropout(p=0.625, inplace=False)\n",
       "    (attention): Attention(\n",
       "      (attn): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      (v): Linear(in_features=1024, out_features=1, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (attn): Linear(in_features=1536, out_features=512, bias=True)\n",
       "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
       "    )\n",
       "    (embedding): Embedding(5893, 256)\n",
       "    (rnn): GRU(1280, 512)\n",
       "    (fc_out): Linear(in_features=1792, out_features=5893, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "            \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bbhX34STL1uc",
    "outputId": "3065f31e-7b3a-4816-d921-71750d833869"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 26,289,669 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "N6OVmu6eL-Pu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "Qw3UeEbL3oVK"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "MG_lXUR13oVQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "zr4TvS4dMLrD"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    with torch.autograd.set_detect_anomaly(True):\n",
    "        print('no. of batches:', len(iterator))\n",
    "        for i, batch in enumerate(iterator):\n",
    "            src, src_len = batch.src\n",
    "            #print('batch_no:',i+1,'max_len:',max(src_len),'min_len',min(src_len))\n",
    "            trg = batch.trg\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(src, src_len, trg)\n",
    "            \n",
    "            #trg = [trg len, batch size]\n",
    "            #output = [trg len, batch size, output dim]\n",
    "            \n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "            \n",
    "            #trg = [(trg len - 1) * batch size]\n",
    "            #output = [(trg len - 1) * batch size, output dim]\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        return epoch_loss / len(iterator)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "Wo8IlBkzMRFC"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            src, src_len = batch.src\n",
    "            print('batch_no:',i+1,'max_len:',max(src_len),'min_len',min(src_len))\n",
    "            trg = batch.trg\n",
    "\n",
    "            output = model(src, src_len, trg, 0) #turn off teacher forcing\n",
    "            \n",
    "            #trg = [trg len, batch size]\n",
    "            #output = [trg len, batch size, output dim]\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            #trg = [(trg len - 1) * batch size]\n",
    "            #output = [(trg len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "QAEozws8T2uG"
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = (elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-jPt1PJGnmhk",
    "outputId": "76fb07dc-6732-415c-e289-e18c0e1cafa4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of batches: 227\n",
      "batch_no: 1 max_len: tensor(10, device='cuda:0') min_len tensor(5, device='cuda:0')\n",
      "batch_no: 2 max_len: tensor(12, device='cuda:0') min_len tensor(10, device='cuda:0')\n",
      "batch_no: 3 max_len: tensor(13, device='cuda:0') min_len tensor(12, device='cuda:0')\n",
      "batch_no: 4 max_len: tensor(14, device='cuda:0') min_len tensor(13, device='cuda:0')\n",
      "batch_no: 5 max_len: tensor(15, device='cuda:0') min_len tensor(14, device='cuda:0')\n",
      "batch_no: 6 max_len: tensor(17, device='cuda:0') min_len tensor(15, device='cuda:0')\n",
      "batch_no: 7 max_len: tensor(20, device='cuda:0') min_len tensor(17, device='cuda:0')\n",
      "batch_no: 8 max_len: tensor(35, device='cuda:0') min_len tensor(20, device='cuda:0')\n",
      "Epoch: 01 | Time: 3m 19.3422634601593s\n",
      "\tTrain Loss: 5.102 | Train PPL: 164.392\n",
      "\t Val. Loss: 4.789 |  Val. PPL: 120.160\n",
      "no. of batches: 227\n",
      "batch_no: 1 max_len: tensor(10, device='cuda:0') min_len tensor(5, device='cuda:0')\n",
      "batch_no: 2 max_len: tensor(12, device='cuda:0') min_len tensor(10, device='cuda:0')\n",
      "batch_no: 3 max_len: tensor(13, device='cuda:0') min_len tensor(12, device='cuda:0')\n",
      "batch_no: 4 max_len: tensor(14, device='cuda:0') min_len tensor(13, device='cuda:0')\n",
      "batch_no: 5 max_len: tensor(15, device='cuda:0') min_len tensor(14, device='cuda:0')\n",
      "batch_no: 6 max_len: tensor(17, device='cuda:0') min_len tensor(15, device='cuda:0')\n",
      "batch_no: 7 max_len: tensor(20, device='cuda:0') min_len tensor(17, device='cuda:0')\n",
      "batch_no: 8 max_len: tensor(35, device='cuda:0') min_len tensor(20, device='cuda:0')\n",
      "Epoch: 02 | Time: 3m 18.792767763137817s\n",
      "\tTrain Loss: 4.084 | Train PPL:  59.364\n",
      "\t Val. Loss: 4.212 |  Val. PPL:  67.510\n",
      "no. of batches: 227\n",
      "batch_no: 1 max_len: tensor(10, device='cuda:0') min_len tensor(5, device='cuda:0')\n",
      "batch_no: 2 max_len: tensor(12, device='cuda:0') min_len tensor(10, device='cuda:0')\n",
      "batch_no: 3 max_len: tensor(13, device='cuda:0') min_len tensor(12, device='cuda:0')\n",
      "batch_no: 4 max_len: tensor(14, device='cuda:0') min_len tensor(13, device='cuda:0')\n",
      "batch_no: 5 max_len: tensor(15, device='cuda:0') min_len tensor(14, device='cuda:0')\n",
      "batch_no: 6 max_len: tensor(17, device='cuda:0') min_len tensor(15, device='cuda:0')\n",
      "batch_no: 7 max_len: tensor(20, device='cuda:0') min_len tensor(17, device='cuda:0')\n",
      "batch_no: 8 max_len: tensor(35, device='cuda:0') min_len tensor(20, device='cuda:0')\n",
      "Epoch: 03 | Time: 3m 18.594207048416138s\n",
      "\tTrain Loss: 3.428 | Train PPL:  30.821\n",
      "\t Val. Loss: 3.813 |  Val. PPL:  45.285\n",
      "no. of batches: 227\n",
      "batch_no: 1 max_len: tensor(10, device='cuda:0') min_len tensor(5, device='cuda:0')\n",
      "batch_no: 2 max_len: tensor(12, device='cuda:0') min_len tensor(10, device='cuda:0')\n",
      "batch_no: 3 max_len: tensor(13, device='cuda:0') min_len tensor(12, device='cuda:0')\n",
      "batch_no: 4 max_len: tensor(14, device='cuda:0') min_len tensor(13, device='cuda:0')\n",
      "batch_no: 5 max_len: tensor(15, device='cuda:0') min_len tensor(14, device='cuda:0')\n",
      "batch_no: 6 max_len: tensor(17, device='cuda:0') min_len tensor(15, device='cuda:0')\n",
      "batch_no: 7 max_len: tensor(20, device='cuda:0') min_len tensor(17, device='cuda:0')\n",
      "batch_no: 8 max_len: tensor(35, device='cuda:0') min_len tensor(20, device='cuda:0')\n",
      "Epoch: 04 | Time: 3m 17.51512861251831s\n",
      "\tTrain Loss: 3.010 | Train PPL:  20.285\n",
      "\t Val. Loss: 3.565 |  Val. PPL:  35.324\n",
      "no. of batches: 227\n",
      "batch_no: 1 max_len: tensor(10, device='cuda:0') min_len tensor(5, device='cuda:0')\n",
      "batch_no: 2 max_len: tensor(12, device='cuda:0') min_len tensor(10, device='cuda:0')\n",
      "batch_no: 3 max_len: tensor(13, device='cuda:0') min_len tensor(12, device='cuda:0')\n",
      "batch_no: 4 max_len: tensor(14, device='cuda:0') min_len tensor(13, device='cuda:0')\n",
      "batch_no: 5 max_len: tensor(15, device='cuda:0') min_len tensor(14, device='cuda:0')\n",
      "batch_no: 6 max_len: tensor(17, device='cuda:0') min_len tensor(15, device='cuda:0')\n",
      "batch_no: 7 max_len: tensor(20, device='cuda:0') min_len tensor(17, device='cuda:0')\n",
      "batch_no: 8 max_len: tensor(35, device='cuda:0') min_len tensor(20, device='cuda:0')\n",
      "Epoch: 05 | Time: 3m 18.887282371520996s\n",
      "\tTrain Loss: 2.656 | Train PPL:  14.233\n",
      "\t Val. Loss: 3.435 |  Val. PPL:  31.016\n",
      "no. of batches: 227\n",
      "batch_no: 1 max_len: tensor(10, device='cuda:0') min_len tensor(5, device='cuda:0')\n",
      "batch_no: 2 max_len: tensor(12, device='cuda:0') min_len tensor(10, device='cuda:0')\n",
      "batch_no: 3 max_len: tensor(13, device='cuda:0') min_len tensor(12, device='cuda:0')\n",
      "batch_no: 4 max_len: tensor(14, device='cuda:0') min_len tensor(13, device='cuda:0')\n",
      "batch_no: 5 max_len: tensor(15, device='cuda:0') min_len tensor(14, device='cuda:0')\n",
      "batch_no: 6 max_len: tensor(17, device='cuda:0') min_len tensor(15, device='cuda:0')\n",
      "batch_no: 7 max_len: tensor(20, device='cuda:0') min_len tensor(17, device='cuda:0')\n",
      "batch_no: 8 max_len: tensor(35, device='cuda:0') min_len tensor(20, device='cuda:0')\n",
      "Epoch: 06 | Time: 3m 18.398483753204346s\n",
      "\tTrain Loss: 2.410 | Train PPL:  11.135\n",
      "\t Val. Loss: 3.398 |  Val. PPL:  29.892\n",
      "no. of batches: 227\n",
      "batch_no: 1 max_len: tensor(10, device='cuda:0') min_len tensor(5, device='cuda:0')\n",
      "batch_no: 2 max_len: tensor(12, device='cuda:0') min_len tensor(10, device='cuda:0')\n",
      "batch_no: 3 max_len: tensor(13, device='cuda:0') min_len tensor(12, device='cuda:0')\n",
      "batch_no: 4 max_len: tensor(14, device='cuda:0') min_len tensor(13, device='cuda:0')\n",
      "batch_no: 5 max_len: tensor(15, device='cuda:0') min_len tensor(14, device='cuda:0')\n",
      "batch_no: 6 max_len: tensor(17, device='cuda:0') min_len tensor(15, device='cuda:0')\n",
      "batch_no: 7 max_len: tensor(20, device='cuda:0') min_len tensor(17, device='cuda:0')\n",
      "batch_no: 8 max_len: tensor(35, device='cuda:0') min_len tensor(20, device='cuda:0')\n",
      "Epoch: 07 | Time: 3m 15.93808126449585s\n",
      "\tTrain Loss: 2.152 | Train PPL:   8.606\n",
      "\t Val. Loss: 3.454 |  Val. PPL:  31.639\n",
      "no. of batches: 227\n",
      "batch_no: 1 max_len: tensor(10, device='cuda:0') min_len tensor(5, device='cuda:0')\n",
      "batch_no: 2 max_len: tensor(12, device='cuda:0') min_len tensor(10, device='cuda:0')\n",
      "batch_no: 3 max_len: tensor(13, device='cuda:0') min_len tensor(12, device='cuda:0')\n",
      "batch_no: 4 max_len: tensor(14, device='cuda:0') min_len tensor(13, device='cuda:0')\n",
      "batch_no: 5 max_len: tensor(15, device='cuda:0') min_len tensor(14, device='cuda:0')\n",
      "batch_no: 6 max_len: tensor(17, device='cuda:0') min_len tensor(15, device='cuda:0')\n",
      "batch_no: 7 max_len: tensor(20, device='cuda:0') min_len tensor(17, device='cuda:0')\n",
      "batch_no: 8 max_len: tensor(35, device='cuda:0') min_len tensor(20, device='cuda:0')\n",
      "Epoch: 08 | Time: 3m 16.626136541366577s\n",
      "\tTrain Loss: 1.989 | Train PPL:   7.308\n",
      "\t Val. Loss: 3.460 |  Val. PPL:  31.805\n",
      "no. of batches: 227\n",
      "batch_no: 1 max_len: tensor(10, device='cuda:0') min_len tensor(5, device='cuda:0')\n",
      "batch_no: 2 max_len: tensor(12, device='cuda:0') min_len tensor(10, device='cuda:0')\n",
      "batch_no: 3 max_len: tensor(13, device='cuda:0') min_len tensor(12, device='cuda:0')\n",
      "batch_no: 4 max_len: tensor(14, device='cuda:0') min_len tensor(13, device='cuda:0')\n",
      "batch_no: 5 max_len: tensor(15, device='cuda:0') min_len tensor(14, device='cuda:0')\n",
      "batch_no: 6 max_len: tensor(17, device='cuda:0') min_len tensor(15, device='cuda:0')\n",
      "batch_no: 7 max_len: tensor(20, device='cuda:0') min_len tensor(17, device='cuda:0')\n",
      "batch_no: 8 max_len: tensor(35, device='cuda:0') min_len tensor(20, device='cuda:0')\n",
      "Epoch: 09 | Time: 3m 17.922316789627075s\n",
      "\tTrain Loss: 1.820 | Train PPL:   6.173\n",
      "\t Val. Loss: 3.456 |  Val. PPL:  31.678\n",
      "no. of batches: 227\n",
      "batch_no: 1 max_len: tensor(10, device='cuda:0') min_len tensor(5, device='cuda:0')\n",
      "batch_no: 2 max_len: tensor(12, device='cuda:0') min_len tensor(10, device='cuda:0')\n",
      "batch_no: 3 max_len: tensor(13, device='cuda:0') min_len tensor(12, device='cuda:0')\n",
      "batch_no: 4 max_len: tensor(14, device='cuda:0') min_len tensor(13, device='cuda:0')\n",
      "batch_no: 5 max_len: tensor(15, device='cuda:0') min_len tensor(14, device='cuda:0')\n",
      "batch_no: 6 max_len: tensor(17, device='cuda:0') min_len tensor(15, device='cuda:0')\n",
      "batch_no: 7 max_len: tensor(20, device='cuda:0') min_len tensor(17, device='cuda:0')\n",
      "batch_no: 8 max_len: tensor(35, device='cuda:0') min_len tensor(20, device='cuda:0')\n",
      "Epoch: 10 | Time: 3m 17.1318097114563s\n",
      "\tTrain Loss: 1.695 | Train PPL:   5.445\n",
      "\t Val. Loss: 3.506 |  Val. PPL:  33.303\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut4-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CjVyWdFxZECe",
    "outputId": "14d9c9c1-904c-4bd9-f080-6cf5ba4683dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_no: 1 max_len: tensor(10, device='cuda:0') min_len tensor(7, device='cuda:0')\n",
      "batch_no: 2 max_len: tensor(11, device='cuda:0') min_len tensor(10, device='cuda:0')\n",
      "batch_no: 3 max_len: tensor(12, device='cuda:0') min_len tensor(11, device='cuda:0')\n",
      "batch_no: 4 max_len: tensor(13, device='cuda:0') min_len tensor(12, device='cuda:0')\n",
      "batch_no: 5 max_len: tensor(15, device='cuda:0') min_len tensor(14, device='cuda:0')\n",
      "batch_no: 6 max_len: tensor(16, device='cuda:0') min_len tensor(15, device='cuda:0')\n",
      "batch_no: 7 max_len: tensor(19, device='cuda:0') min_len tensor(16, device='cuda:0')\n",
      "batch_no: 8 max_len: tensor(33, device='cuda:0') min_len tensor(19, device='cuda:0')\n",
      "| Test Loss: 3.372 | Test PPL:  29.132 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('tut4-model.pt'))\n",
    "\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "UfuDelLbb7Tp"
   },
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
    "\n",
    "    model.eval()\n",
    "        \n",
    "    if isinstance(sentence, str):\n",
    "        nlp = spacy.load('de')\n",
    "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
    "        \n",
    "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
    "    \n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
    "\n",
    "    src_len = torch.LongTensor([len(src_indexes)]).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, hidden,masks = model.encoder(src_tensor, src_len)\n",
    "\n",
    "    mask = model.create_mask(src_tensor)\n",
    "        \n",
    "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
    "\n",
    "    #attentions = torch.zeros(max_len, 1, len(src_indexes)).to(device)\n",
    "    \n",
    "    for i in range(max_len):\n",
    "\n",
    "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
    "                \n",
    "        with torch.no_grad():\n",
    "            output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs, masks)\n",
    "\n",
    "        #attentions[i] = attention\n",
    "            \n",
    "        pred_token = output.argmax(1).item()\n",
    "        \n",
    "        trg_indexes.append(pred_token)\n",
    "\n",
    "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
    "            break\n",
    "    \n",
    "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
    "    \n",
    "    return trg_tokens[1:]#, attentions[:len(trg_tokens)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "KXkJLcNcJrQ6"
   },
   "outputs": [],
   "source": [
    "def display_attention(sentence, translation, attention):\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
    "    \n",
    "    cax = ax.matshow(attention, cmap='bone')\n",
    "   \n",
    "    ax.tick_params(labelsize=15)\n",
    "    ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \n",
    "                       rotation=45)\n",
    "    ax.set_yticklabels(['']+translation)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6AYpGdZbyJZX",
    "outputId": "2e0c0284-7e16-4ca8-8512-539e22ff2d75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src = ['ein', 'schwarzer', 'hund', 'und', 'ein', 'gefleckter', 'hund', 'kämpfen', '.']\n",
      "trg = ['a', 'black', 'dog', 'and', 'a', 'spotted', 'dog', 'are', 'fighting']\n"
     ]
    }
   ],
   "source": [
    "example_idx = 12\n",
    "\n",
    "src = vars(train_data.examples[example_idx])['src']\n",
    "trg = vars(train_data.examples[example_idx])['trg']\n",
    "\n",
    "print(f'src = {src}')\n",
    "print(f'trg = {trg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k1CyuzO4yUgR",
    "outputId": "9527b515-337d-401d-eced-0fd80be95b59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted trg = ['a', 'black', 'dog', 'and', 'a', 'spotted', 'dog', 'fighting', '.', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "#translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
    "translation = translate_sentence(src, SRC, TRG, model, device)\n",
    "\n",
    "print(f'predicted trg = {translation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WDnPB9NKyVoH",
    "outputId": "1bb79541-2e11-46ef-f4ca-c1b643071aec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src = ['eine', 'frau', 'spielt', 'ein', 'lied', 'auf', 'ihrer', 'geige', '.']\n",
      "trg = ['a', 'female', 'playing', 'a', 'song', 'on', 'her', 'violin', '.']\n"
     ]
    }
   ],
   "source": [
    "example_idx = 14\n",
    "\n",
    "src = vars(valid_data.examples[example_idx])['src']\n",
    "trg = vars(valid_data.examples[example_idx])['trg']\n",
    "\n",
    "print(f'src = {src}')\n",
    "print(f'trg = {trg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "59x436hsybUL",
    "outputId": "50a9a2bd-caba-4849-d97c-53250116a74b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted trg = ['a', 'woman', 'is', 'playing', 'a', 'violin', 'on', 'violin', '.', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "#translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
    "translation = translate_sentence(src, SRC, TRG, model, device)\n",
    "\n",
    "print(f'predicted trg = {translation}')\n",
    "\n",
    "#display_attention(src, translation, attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vclvJH26ycYU",
    "outputId": "591a7a51-3f83-4c44-826c-8985c3745939"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src = ['die', 'person', 'im', 'gestreiften', 'shirt', 'klettert', 'auf', 'einen', 'berg', '.']\n",
      "trg = ['the', 'person', 'in', 'the', 'striped', 'shirt', 'is', 'mountain', 'climbing', '.']\n"
     ]
    }
   ],
   "source": [
    "example_idx = 18\n",
    "\n",
    "src = vars(test_data.examples[example_idx])['src']\n",
    "trg = vars(test_data.examples[example_idx])['trg']\n",
    "\n",
    "print(f'src = {src}')\n",
    "print(f'trg = {trg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gW0a1omnyeZo",
    "outputId": "a3d7f87e-5bbe-4318-d9fb-782e9f23a9ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted trg = ['the', 'person', 'in', 'a', 'striped', 'shirt', 'is', 'climbing', 'a', 'rock', '.', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "#translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
    "translation = translate_sentence(src, SRC, TRG, model, device)\n",
    "\n",
    "print(f'predicted trg = {translation}')\n",
    "\n",
    "#display_attention(src, translation, attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "wvOxmxlbyhi7"
   },
   "outputs": [],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "def calculate_bleu(data, src_field, trg_field, model, device, max_len = 50):\n",
    "    \n",
    "    trgs = []\n",
    "    pred_trgs = []\n",
    "    \n",
    "    for datum in data:\n",
    "        \n",
    "        src = vars(datum)['src']\n",
    "        trg = vars(datum)['trg']\n",
    "        \n",
    "        #pred_trg, _ = translate_sentence(src, src_field, trg_field, model, device, max_len)\n",
    "        pred_trg = translate_sentence(src, src_field, trg_field, model, device, max_len)\n",
    "        \n",
    "        #cut off <eos> token\n",
    "        pred_trg = pred_trg[:-1]\n",
    "        \n",
    "        pred_trgs.append(pred_trg)\n",
    "        trgs.append([trg])\n",
    "        \n",
    "    return bleu_score(pred_trgs, trgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5aT5BPwYym1K",
    "outputId": "3e6c6c56-839d-430f-8dcf-7b2cb84b1b46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score = 22.70\n"
     ]
    }
   ],
   "source": [
    "bleu_score = calculate_bleu(test_data, SRC, TRG, model, device)\n",
    "\n",
    "print(f'BLEU score = {bleu_score*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "6tdxBtlOFCE1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ADL-conv",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
